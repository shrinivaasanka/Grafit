##############################################################################################################################################
<a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons Licence" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License</a>.
##############################################################################################################################################
Course Authored By:
-----------------------------------------------------------------------------------------------------------
K.Srinivasan
Personal website(research): https://sites.google.com/site/kuja27/
NeuronRain GitHub and SourceForge Documentation: http://neuronrain-documentation.readthedocs.io/
-----------------------------------------------------------------------------------------------------------
##############################################################################################################################################

This is a non-linearly organized, continually updated set of course notes on miscellaneous topics in Graduate/Doctoral level
Computer Science and Machine Learning and supplements NeuronRain AsFer Design Notes in:
----------------------------------------------------------------------------------------------------------------------------
NeuronRain Enterprise Version Design Documents:
-----------------------------------------------
AsFer Machine Learning - https://github.com/shrinivaasanka/asfer-github-code/blob/master/asfer-docs/AstroInferDesign.txt
-----------------------------------------------
NeuronRain Research Version Design Documents:
-----------------------------------------------
AsFer Machine Learning - https://sourceforge.net/p/asfer/code/HEAD/tree/asfer-docs/AstroInferDesign.txt
----------------------------------------------------------------------------------------------------------------------------
9 March 2017
----------------------------------------------------------------------------------------------------------------------------
Recurrent Neural Network - Long Term Short Term Memory:
-------------------------------------------------------
Traditional neural networks have a threshold function which outputs 1 or 0 based on a threshold. But they don't preserve state information
over points in time. For example, if there is a requirement that next state depends on present state and an input, usual neural network
cannot satisfy it. Recurrent Neural Networks fill this void through ability to feedback while traditional neural network is feedforward.
LongTerm-ShortTerm memory Recurrent Neural Networks are defined with schematic below:

	Forget gate --------------> * <-------------- + ---------------> * ------------->
				    |---------------->|			/|\
						     /|\		 |
						      |			 |
	Cell gate ----------------> * --------------->|			 |
				   /|\					 |
				    |					 |
	Input gate -----------------|					 |
									 |
	Output gate ------------------------------------------------------

It has four gates: Forget gate, Cell gate, Input gate and Output gate and has a recurrence/feedback as shown in first line between Forget,
Cell and Input gates. * is per-element product and + is per-element sum of vectors.

-------------------------------------------------------------------
Recurrent Neural Network - Gated Recurrent Unit:
-------------------------------------------------------------------
A slight variation of RNN LSTM diagram previously is RNN Gated Recurrent Unit (GRU). It lacks an output gate and merges the functionality
of input gates into two gates - reset and update - as drawn in schematic below:

h(t-1)-------------------> * --------------> Ct ----------------> * -------------------> h(t)
	|		   /\ 	 	      /\                   /\
	|		   | 		      | 		   |
	|	reset	   * <----------------x------------------->* update
	|		  /|\		      			  /|\
	|		   |		      			   |
	V------------------|---------------------------------------|

with equations:
	ut = sigmoid(Vu*xt + Wu*h(t-1) + bu)
	rt = sigmoid(Vr*xt + Wr*h(t-1) + br)
	Ct = tanh(Vc*xt + Wc*(h(t-1) * rt))
	ht = (1-ut)*Ct + ut*h(t-1)
where ut = update gate,
      rt = reset gate,
      Ct = cell gate
      ht = state at time t
      Vu,Vr,Vc,Wu,Wr,Wc are weight vectors.

Both above have been implemented in:
https://github.com/shrinivaasanka/asfer-github-code/blob/master/python-src/DeepLearning_LSTMRecurrentNeuralNetwork.py
https://github.com/shrinivaasanka/asfer-github-code/blob/master/python-src/DeepLearning_GRURecurrentNeuralNetwork.py

--------------------------------------------------------------------------------------------------------------------------------------
Mathematical Puzzles of Sam Loyd (selected and edited by Martin Gardner) - Puzzle 18 - What is the most economical form of a tank
designed to hold 1000 cubic feet? - 26 January 2018
--------------------------------------------------------------------------------------------------------------------------------------
A Plumber wanted to estimate the lowest possible cost of a copper tank to hold 1000 cubic feet. Copper costs $1 per square foot. Problem
is to determine most economical dimensions of the rectangular tank of capacity 1000 cubic feet. Trivial solution of 10 feet * 10 feet *
10 feet = 1000 cubic feet tank costs $500 of copper surface (100 in bottom + 4*100 in sides). Another solution which costs less than
$500 for copper surfacing is expected.

Plumber's problem has applications in packing/knapsack algorithms which minimize the cost of packing items in least volume. This is also
equivalent to storing set of 1000 elements in a 3 dimensional array (cube) subject to minimizing the objective function xy + 2z(x+y) and constraint xyz = 1000 for array indices x,y,z.

This problem can be cast into a (Multi)Linear Program formulation - sums of products 
Let l,b,h be the length,breadth and height of the tank.

The objective cost function for copper plating the surface to be minimized is:
	l*b + 2*h*l + 2*h*b = cost
subject to constraint:
	l*b*h = 1000 

Objective function can be rewritten as:
	1000/h + 2h(l + b) = cost

Solving multilinear programs is non-trivial requiring reformulation and linearization creating a new LP(RL algorithms).  

------------------------
1. (l+b) is a constant:
------------------------
If (l+b) = sum of sides of rectangles is fixed to be a constant elementary calculus can solve this:
first derivative of cost function is equated to zero:
	d(cost)/dh = -1000/h^2 + 2(l+b) = 0
	2(l+b) = 1000/h^2
	h^2 = 1000/[2(l+b)]
	h = 22.36068/sqrt(l+b)
[ => lbh = lb*22.36068/sqrt(l+b) = 1000, lb/sqrt(l+b) = 1000/22.36068 = 44.72 ]

Second derivative of cost function is positive, implying a local minima. Thus if height of the tank h is inversely related to square root of sum of length and breadth of bottom rectangle as h = 22.36/sqrt(l+b), cost of copper plating is minimized. If bottom is a square, l = b and
h = 22.36/(1.414*sqrt(l)) = 15.811/sqrt(l).

=> lbh = ll*15.811/sqrt(l) = 15.811*l*sqrt(l) = 1000
=> l^1.5 = 1000/15.811 = 63.247
=> 1.5 log l = log 63.247
=> l = 15.874
=> h = 15.811/sqrt(15.874) = 3.968

Dimensions of the tank of least copper plating cost by local mimima = 15.874 * 15.874 * 3.968 
Cost = 500 which is not less than 10 * 10 * 10.

---------------------------------------------
2. Bottom is a square and is a function of h:
---------------------------------------------
Bottom is square : l=b=kh
Cost function: kh*kh + 2h*kh + 2h*kh = k^2*h^2 + 4k*h^2
Cost = (k^2 + 4k) * h^2
Volume = lbh = kh*kh*h = k^2*h^3 = 1000
=> h^3 = 1000/(k^2)

Cost = (k^2 + 4k) * (1000)^0.66/k^1.33) = (k^2 + 4k)/k^1.33 * 95.49926
Cost = (k^0.66 + 4k^(-0.33)) * 95.49926
d(Cost)/dk = 0.66*k^(-0.33) - 1.33*k^(-1.33) = 0
=> minima at k = 2.

Dimensions are 2h*2h*h and 
Cost is 12h^2 = 476.21 for h=6.2966

-------------
Book Solution: 
-------------
If bottom is a square of side = 2h for height h, economical cost is attained.
=> 2h*2h*h = 4h^3 = 1000
=> h = 6.2996
Cost = 4h^2 + 2h(4h) = 12h^2 = 12*(6.2996)^2 = 476.21  

Reference:
---------
Mathematical Puzzles of SAM LOYD - Selected and Edited by MARTIN GARDNER

-------------------------------------------------------------------------------------------------------------------------------------------
Catalan Numbers - How many squares and lattice paths are in a grid e.g 4 * 4 - Puzzle 142 - Puzzles To Puzzle You - 
Shakuntala Devi - 26 January 2018
-------------------------------------------------------------------------------------------------------------------------------------------
In a grid of 4 * 4, number of possible squares are obtained by moving a sliding 2 dimensional square window left-right, top-down as in
algorithm below:
	for square sliding window size w*w
	{
		slide window top-down
		{	
			slide window left-right 
			number_of_squares += 1
		}
		w = w+1
	}
Sliding window square increases in size from 1*1 to 4*4.
Number of squares of size 1*1 = 16 = 4*4
Number of squares of size 2*2 = 9  = 3*3
Number of squares of size 3*3 = 4  = 2*2
Number of squares of size 4*4 = 1  = 1*1
			-----------
			Total = 30
			-----------
Generic series is = 1 + 2^2 + 3^2 + ... + n^2

Number of lattice paths in the grid which lead from bottom left to top right of the grid is the Catalan Number = 1/(n+1) * 2nCn which is
same as number of Dyck words of the form XXYXX,... number of possible rooted binary trees of node size n and number of possible balanced 
parenthesizations of an infix arithmetic expression. Catalan numbers are ubiquitous in combinatorial algorithms involving recursions and
self-similarity. Catalan number is also the number of random walks in the grid graph.

Most celebrated result involving Catalan numbers is the Bertrand Ballot Theorem: In an election of two candidates A and B, if A receives
p votes and B receives q votes, p > q, what is the probability A is strictly ahead of B throughout counting? This problem reduces to counting
dyck paths in the grid (time versus votes). Ballot Theorem applies to Streaming binary datasets and gives the probability of 1s dominating the stream if 1s outnumber 0s and vice versa.

Reference:
---------
Puzzles To Puzzle You - Shakuntala Devi 

-------------------------------------------------------------------------------------------------------------------------------------
Binary Search of a sorted array containing gaps - 6 February 2018
-------------------------------------------------------------------------------------------------------------------------------------
Q:Usual binary searches are made on arrays of contiguous sorted elements. How can binary search be made to work if the array has gaps/holes
and yet the contents are in sorted order? E.g Array 12,33,44,-,-,56,-,66,-,-,-,88,99,-,-,123 is sorted ascending but has gaps.

A1: One possible solution is to fill the gaps with placeholder numbers or replicate the integers in hole boundaries to fill the gap. Previous
example array is filled as 12,33,44,44,44,56,56,66,66,66,66,88,99,99,99,123.
A2: Other possibility is to fill the gaps with an arithmetic progression on difference of the integers on the boundaries. Previous example array is filled as 12,33,44,48,52,56,61,66,...
A3: Filling is necessary because to choose the subtree of search, an integer is necessary. Non-filling solution has to branch off to a subtree based on some other meta data on the gaps. Alternative: when a "-" is found, scan the array in one direction till an integer appears and branch off. This is similar to open addressing in hash tables. But this linear scan increases the amortized binary search cost from O(logN) to something higher. But filling the gaps by placeholders or arithmetic progressions is also linear and makes binary search superlogarithmic.

This problem has applications in splitting a single huge sorted array into multiple smaller arrays, distributed geographically but logically mapped to virtual memory pages in single address space, and searching them.

---------------------------------------------------------------------------------------------------------------------------------------
Sublinear Multiple String Concatenation - 8 February 2018
---------------------------------------------------------------------------------------------------------------------------------------
Q: Concatenation of multiple strings is trivially doable in O(N). Can N strings be concatenated in sublinear time?

A: Subject to certain assumptions following algorithm does sublinear multiple string concatenation:

Let the number of strings be N each of length l. Each string is fingerprinted/compressed to length logN by a standard algorithm e.g Rabin string fingerprint which computes a polynomial of degree l over Galois Field GF(2) and divides this by an irreducible polynomial of degree logN over GF(2) to create a fingerprint of logN-bit length. 

Create a matrix of logN * N (transpose) which has logN rows and as many columns as number of strings. Entries of this matrix are the bits of string fingerprint hashes. This transformation converts N strings of length l to logN strings of length N. Hashes are stored as Rope strings to facilitate logN time pairwise computation. These logN strings are concatenated as a binary tree bottom-up and each pairwise concatenation is O(logN). Following series sums up the runtime:
	logN*(logN/2 + logN/4 + logN/8 + logN/16 + ...)
	= logN*logN*2 
	= 2(logN)^2
This indirectly concatenates N strings in O(logN*logN) time. But it messes up with original string. This requires slight modification to pairwise Rope string concatenation routine. Before concatenation hash has to be reverse engineered (Rabin fingerprint polynomials have to be stored) to unicode string and location in the resultant single concatenation has to be ingredient of this routine. 

Fingerprinting is not a necessity. Without fingerprint, previous matrix is l * N (l strings of length N) and the concatenation tree has following runtime geometric recurrence:
	logN*(l/2 + l/4 + l/8 + l/16 + ...) 
	[because each internal node of concatenation tree needs O(logN) time for 2 Rope string concatenation]
	= logN*2l 
	= 2*l*logN

This runtime is sublinear if:
	2*l*logN < N
	length of each string = l < N/(2*logN)
